{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "399b3e40",
   "metadata": {},
   "source": [
    "# Extract Detailed Species Information from Vietnamese Red List\n",
    "\n",
    "This notebook fetches detailed information for each species from their individual pages on the Vietnamese Red List website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c217bcc4",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a30843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phucle/Desktop/Code/conservation/conservation-law-lookup/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, Optional, List\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a5a48",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "110cc1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Headers to mimic a browser request\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "}\n",
    "\n",
    "# Input file containing species links\n",
    "INPUT_CSV = 'vnredlist_all_species_links.csv'\n",
    "\n",
    "# Output file for detailed species data\n",
    "OUTPUT_JSON = 'vnredlist_species_details.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db238a",
   "metadata": {},
   "source": [
    "## 3. Helper Functions to Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5d6ca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_species_page(url: str) -> Optional[BeautifulSoup]:\n",
    "    \"\"\"\n",
    "    Fetch a species page and return BeautifulSoup object.\n",
    "    \n",
    "    Args:\n",
    "        url: The species page URL\n",
    "    \n",
    "    Returns:\n",
    "        BeautifulSoup object or None if failed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=15)\n",
    "        response.raise_for_status()\n",
    "        return BeautifulSoup(response.content, 'html.parser')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"âœ— Error fetching {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c220b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_after_heading(soup: BeautifulSoup, heading_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract text content after a specific heading.\n",
    "    \n",
    "    Args:\n",
    "        soup: BeautifulSoup object\n",
    "        heading_text: The heading text to search for\n",
    "    \n",
    "    Returns:\n",
    "        Extracted text or empty string\n",
    "    \"\"\"\n",
    "    # Find the heading (h3, h4, etc.)\n",
    "    headings = soup.find_all(['h3', 'h4'])\n",
    "    \n",
    "    for heading in headings:\n",
    "        heading_content = heading.get_text(strip=True)\n",
    "        if heading_text.lower() in heading_content.lower():\n",
    "            # Get the next sibling element\n",
    "            next_elem = heading.find_next_sibling()\n",
    "            if next_elem:\n",
    "                # Get text with proper spacing\n",
    "                text = next_elem.get_text(separator=' ', strip=True)\n",
    "                # Clean up multiple spaces\n",
    "                text = ' '.join(text.split())\n",
    "                return text\n",
    "    \n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9526976b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_page_structure(soup: BeautifulSoup):\n",
    "    \"\"\"\n",
    "    Debug function to inspect the page structure.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== Page Structure Analysis ===\")\n",
    "    \n",
    "    # Find all h3 and h4 headings\n",
    "    print(\"\\nAll H3/H4 headings found:\")\n",
    "    for heading in soup.find_all(['h3', 'h4'])[:20]:  # Limit to first 20\n",
    "        text = heading.get_text(strip=True)\n",
    "        next_elem = heading.find_next_sibling()\n",
    "        next_text = next_elem.get_text(strip=True)[:100] if next_elem else \"None\"\n",
    "        print(f\"  â€¢ {text}\")\n",
    "        print(f\"    â†’ {next_text}\")\n",
    "    \n",
    "    print(\"\\n=== End of Structure Analysis ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f2aec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_taxonomic_info(soup: BeautifulSoup) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Extract taxonomic classification information.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with taxonomic ranks\n",
    "    \"\"\"\n",
    "    taxonomy = {\n",
    "        'kingdom_latin': '',\n",
    "        'kingdom_vi': '',\n",
    "        'phylum_latin': '',\n",
    "        'phylum_vi': '',\n",
    "        'class_latin': '',\n",
    "        'class_vi': '',\n",
    "        'order_latin': '',\n",
    "        'order_vi': '',\n",
    "        'family_latin': '',\n",
    "        'family_vi': ''\n",
    "    }\n",
    "    \n",
    "    # Map Vietnamese headings to taxonomy keys (exact matches)\n",
    "    taxonomy_map = {\n",
    "        'Giá»›i': 'kingdom',\n",
    "        'NgÃ nh': 'phylum',\n",
    "        'Lá»›p': 'class',\n",
    "        'Bá»™': 'order',\n",
    "        'Há»': 'family'\n",
    "    }\n",
    "    \n",
    "    # Find the taxonomy section (usually under \"PhÃ¢n loáº¡i\")\n",
    "    headings = soup.find_all(['h3', 'h4'])\n",
    "    \n",
    "    for heading in headings:\n",
    "        heading_text = heading.get_text(strip=True)\n",
    "        \n",
    "        # Check if this heading matches one of our taxonomy levels\n",
    "        for vn_name, en_key in taxonomy_map.items():\n",
    "            if heading_text == vn_name:  # Exact match only\n",
    "                # Get the next sibling element\n",
    "                next_elem = heading.find_next_sibling()\n",
    "                if next_elem:\n",
    "                    value = next_elem.get_text(separator=' ', strip=True)\n",
    "                    value = ' '.join(value.split())  # Clean multiple spaces\n",
    "                    taxonomy[f'{en_key}_latin'] = value.upper()\n",
    "                break\n",
    "    \n",
    "    return taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "769741ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_species_details(url: str, soup: BeautifulSoup) -> Dict:\n",
    "    \"\"\"\n",
    "    Extract all species details from a species page.\n",
    "    \n",
    "    Args:\n",
    "        url: The species page URL\n",
    "        soup: BeautifulSoup object of the page\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with species information\n",
    "    \"\"\"\n",
    "    species_data = {\n",
    "        'scientific_name': {'value': '', 'note': ''},\n",
    "        'common_name': {'value': '', 'note': ''},\n",
    "        'kingdom_latin': '',\n",
    "        'kingdom_vi': '',\n",
    "        'phylum_latin': '',\n",
    "        'phylum_vi': '',\n",
    "        'class_latin': '',\n",
    "        'class_vi': '',\n",
    "        'order_latin': '',\n",
    "        'order_vi': '',\n",
    "        'family_latin': '',\n",
    "        'family_vi': '',\n",
    "        'note': '',\n",
    "        'laws': []\n",
    "    }\n",
    "    \n",
    "    # Extract scientific name (from page title or heading)\n",
    "    title = soup.find('h1')\n",
    "    if title:\n",
    "        sci_name = title.get_text(strip=True)\n",
    "        # Clean scientific name - remove author and year if present in title\n",
    "        # Keep only the first 2-3 words (genus, species, and possibly subspecies)\n",
    "        parts = sci_name.split()\n",
    "        if len(parts) >= 2:\n",
    "            # Check if third word starts with lowercase (subspecies) or uppercase (author)\n",
    "            if len(parts) >= 3 and parts[2][0].islower():\n",
    "                sci_name = ' '.join(parts[:3])\n",
    "            else:\n",
    "                sci_name = ' '.join(parts[:2])\n",
    "        species_data['scientific_name']['value'] = sci_name\n",
    "    \n",
    "    # Extract Vietnamese common name\n",
    "    common_name = extract_text_after_heading(soup, 'TÃªn viá»‡t nam')\n",
    "    if common_name:\n",
    "        species_data['common_name']['value'] = common_name\n",
    "    \n",
    "    # Extract taxonomic information\n",
    "    taxonomy = extract_taxonomic_info(soup)\n",
    "    species_data.update(taxonomy)\n",
    "    \n",
    "    # Extract conservation status from Vietnamese Red List\n",
    "    # Try multiple possible headings\n",
    "    status = extract_text_after_heading(soup, 'PhÃ¢n háº¡ng báº£o tá»“n')\n",
    "    if not status:\n",
    "        status = extract_text_after_heading(soup, 'PhÃ¢n háº¡ng')\n",
    "    \n",
    "    # Extract just the status code (CR, EN, VU, etc.)\n",
    "    if status:\n",
    "        # Look for status codes in the text\n",
    "        status_match = re.search(r'\\b(CR|EN|VU|NT|LC|DD|EW|EX|NE)\\b', status)\n",
    "        if status_match:\n",
    "            status_code = status_match.group(1)\n",
    "            species_data['laws'].append({\n",
    "                'name': {\n",
    "                    'vi': 'Danh lá»¥c Äá» Viá»‡t Nam',\n",
    "                    'en': 'Vietnam Red List'\n",
    "                },\n",
    "                'value': status_code,\n",
    "                'note': url\n",
    "            })\n",
    "    \n",
    "    return species_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40783787",
   "metadata": {},
   "source": [
    "## 4. Load Species Links from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63600ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Loaded 1357 species links from vnredlist_all_species_links.csv\n",
      "Columns: ['scientific_name', 'common_name_vi', 'url', 'category', 'category_url']\n",
      "\n",
      "First few rows:\n",
      "                scientific_name  common_name_vi  \\\n",
      "0               Elephas maximus      Voi chÃ¢u Ã¡   \n",
      "1        Galeopterus variegatus        Chá»“n dÆ¡i   \n",
      "2        Nycticebus bengalensis       Cu li lá»›n   \n",
      "3  Xanthonycticebus intermedius  Cu li miá»n báº¯c   \n",
      "4     Xanthonycticebus pygmaeus       Cu li nhá»   \n",
      "\n",
      "                                                 url  \\\n",
      "0          http://vnredlist.vast.vn/elephas-maximus/   \n",
      "1   http://vnredlist.vast.vn/galeopterus-variegatus/   \n",
      "2   http://vnredlist.vast.vn/nycticebus-bengalensis/   \n",
      "3  http://vnredlist.vast.vn/xanthonycticebus-inte...   \n",
      "4  http://vnredlist.vast.vn/xanthonycticebus-pygm...   \n",
      "\n",
      "                       category  \\\n",
      "0  dong-vat-co-day-song/lop-thu   \n",
      "1  dong-vat-co-day-song/lop-thu   \n",
      "2  dong-vat-co-day-song/lop-thu   \n",
      "3  dong-vat-co-day-song/lop-thu   \n",
      "4  dong-vat-co-day-song/lop-thu   \n",
      "\n",
      "                                        category_url  \n",
      "0  http://vnredlist.vast.vn/dong-vat/dong-vat-co-...  \n",
      "1  http://vnredlist.vast.vn/dong-vat/dong-vat-co-...  \n",
      "2  http://vnredlist.vast.vn/dong-vat/dong-vat-co-...  \n",
      "3  http://vnredlist.vast.vn/dong-vat/dong-vat-co-...  \n",
      "4  http://vnredlist.vast.vn/dong-vat/dong-vat-co-...  \n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file with species links\n",
    "try:\n",
    "    df_species = pd.read_csv(INPUT_CSV)\n",
    "    print(f\"âœ“ Loaded {len(df_species)} species links from {INPUT_CSV}\")\n",
    "    print(f\"Columns: {df_species.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(df_species.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"âœ— File {INPUT_CSV} not found. Please run the fetch_animal_links.ipynb notebook first.\")\n",
    "    df_species = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bc9cb7",
   "metadata": {},
   "source": [
    "## 5. Test with a Single Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be1761f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with: http://vnredlist.vast.vn/xanthonycticebus-intermedius/\n",
      "================================================================================\n",
      "\n",
      "Extracted data:\n",
      "{\n",
      "  \"scientific_name\": {\n",
      "    \"value\": \"Xanthonycticebus intermedius\",\n",
      "    \"note\": \"\"\n",
      "  },\n",
      "  \"common_name\": {\n",
      "    \"value\": \"Cu li miá»n báº¯c\",\n",
      "    \"note\": \"\"\n",
      "  },\n",
      "  \"kingdom_latin\": \"ANIMALIA\",\n",
      "  \"kingdom_vi\": \"\",\n",
      "  \"phylum_latin\": \"CHORDATA\",\n",
      "  \"phylum_vi\": \"\",\n",
      "  \"class_latin\": \"MAMMALIA\",\n",
      "  \"class_vi\": \"\",\n",
      "  \"order_latin\": \"PRIMATES\",\n",
      "  \"order_vi\": \"\",\n",
      "  \"family_latin\": \"LORISIDAE\",\n",
      "  \"family_vi\": \"\",\n",
      "  \"note\": \"\",\n",
      "  \"laws\": [\n",
      "    {\n",
      "      \"name\": {\n",
      "        \"vi\": \"Danh lá»¥c Äá» Viá»‡t Nam\",\n",
      "        \"en\": \"Vietnam Red List\"\n",
      "      },\n",
      "      \"value\": \"EN\",\n",
      "      \"note\": \"http://vnredlist.vast.vn/xanthonycticebus-intermedius/\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "================================================================================\n",
      "Verification:\n",
      "âœ“ Scientific name: Xanthonycticebus intermedius\n",
      "âœ“ Common name: Cu li miá»n báº¯c\n",
      "âœ“ Kingdom: ANIMALIA\n",
      "âœ“ Phylum: CHORDATA\n",
      "âœ“ Class: MAMMALIA\n",
      "âœ“ Order: PRIMATES\n",
      "âœ“ Family: LORISIDAE\n",
      "âœ“ Conservation status: EN\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with the first species\n",
    "if not df_species.empty:\n",
    "    test_url = df_species.iloc[3]['url']\n",
    "    print(f\"Testing with: {test_url}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    test_soup = fetch_species_page(test_url)\n",
    "    if test_soup:\n",
    "        # Extract data\n",
    "        test_data = extract_species_details(test_url, test_soup)\n",
    "        print(\"\\nExtracted data:\")\n",
    "        print(json.dumps(test_data, indent=2, ensure_ascii=False))\n",
    "        \n",
    "        # Verify the extraction\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"Verification:\")\n",
    "        print(f\"âœ“ Scientific name: {test_data['scientific_name']['value']}\")\n",
    "        print(f\"âœ“ Common name: {test_data['common_name']['value']}\")\n",
    "        print(f\"âœ“ Kingdom: {test_data['kingdom_latin']}\")\n",
    "        print(f\"âœ“ Phylum: {test_data['phylum_latin']}\")\n",
    "        print(f\"âœ“ Class: {test_data['class_latin']}\")\n",
    "        print(f\"âœ“ Order: {test_data['order_latin']}\")\n",
    "        print(f\"âœ“ Family: {test_data['family_latin']}\")\n",
    "        if test_data['laws']:\n",
    "            print(f\"âœ“ Conservation status: {test_data['laws'][0]['value']}\")\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(\"Failed to fetch test page\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6482d7",
   "metadata": {},
   "source": [
    "## 6. Process All Species\n",
    "\n",
    "Extract detailed information for all species with proper delays between requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca04d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 1357 species...\n",
      "================================================================================\n",
      "\n",
      "[1/1357] Processing: Elephas maximus\n",
      "\n",
      "[10/1357] Processing: Macaca mulatta\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[20/1357] Processing: Trachypithecus margarita\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[30/1357] Processing: Neohylomys hainanensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[40/1357] Processing: Rhinolophus rex\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[50/1357] Processing: Harpiola isodon\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[60/1357] Processing: Scotomanes ornatus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[70/1357] Processing: Neofelis nebulosa\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[80/1357] Processing: Viverra zibetha\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[90/1357] Processing: Lutra sumatrana\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[100/1357] Processing: Muntiacus vuquangensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[110/1357] Processing: Hylopetes alboniger\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[120/1357] Processing: Tonkinomys daovantieni\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[130/1357] Processing: Rheinartia ocellata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[140/1357] Processing: Houbaropsis bengalensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[150/1357] Processing: Vanellus vanellus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[160/1357] Processing: Numenius madagascariensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[170/1357] Processing: Anhinga melanogaster\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[180/1357] Processing: Aquila clanga\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[190/1357] Processing: Aceros nipalensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[200/1357] Processing: Psittacula eupatria\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[210/1357] Processing: Stachyris herberti\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[220/1357] Processing: Garrulax milleti\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[230/1357] Processing: Cyornis bruneatus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[240/1357] Processing: Leiolepis guttata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[250/1357] Processing: Cnemaspis boulengerii\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[260/1357] Processing: Scincella devorator\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[270/1357] Processing: Coelognathus radiatus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[280/1357] Processing: Subsessor bocourti\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[290/1357] Processing: Naja siamensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[300/1357] Processing: Trimeresurus truongsonensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[310/1357] Processing: Cuora amboinensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[320/1357] Processing: Heosemys annandalii\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[330/1357] Processing: Platysternon megacephalum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[340/1357] Processing: Theloderma annae\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[350/1357] Processing: Odorrana yentuensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[360/1357] Processing: Tylototriton sparreboomi\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[370/1357] Processing: Theloderma nebulosum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[380/1357] Processing: Microhyla pineticola\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[390/1357] Processing: Nanohyla pulchella\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[400/1357] Processing: Amolops viridimaculatus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[410/1357] Processing: Bagarius lica\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[420/1357] Processing: Probarbus jullieni\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[430/1357] Processing: Hippocampus trimaculatus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[440/1357] Processing: Cranoglanis bouderius\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[450/1357] Processing: Schistura nasifilis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[460/1357] Processing: Neolissochilus benasi\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[470/1357] Processing: Catlocarpio siamensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[480/1357] Processing: Narcine brevilabiata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[490/1357] Processing: Squalus japonicus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[500/1357] Processing: Myliobatis tobijei\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[510/1357] Processing: Alopias pelagicus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[520/1357] Processing: Carcharhinus amblyrhynchoides\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[530/1357] Processing: Teinopalpus imperialis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[540/1357] Processing: Atrocalopteryx auco\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[550/1357] Processing: Cheirotonus parryi\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[560/1357] Processing: Cheirotonus jansoni\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[570/1357] Processing: Actias chapae\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[580/1357] Processing: Eosamon nominathuis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[590/1357] Processing: Tachypleus gigas\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[600/1357] Processing: Cypraecassis rufa\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[610/1357] Processing: Pseudobaphia banggiangensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[620/1357] Processing: Pseudodon resupinatus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[630/1357] Processing: Gibbosula crassa\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[640/1357] Processing: Thelenota ananas\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[650/1357] Processing: Plerogyra sinuosa\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[660/1357] Processing: Pavona danai\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[670/1357] Processing: Alveopora verrilliana\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[680/1357] Processing: Galaxea longisepta\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[690/1357] Processing: Acropora donei\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[700/1357] Processing: Heliopora coerulea\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[710/1357] Processing: Isopora cuneata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[720/1357] Processing: Acropora nana\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[730/1357] Processing: Artabotrys tetramerus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[740/1357] Processing: Polyalthia praeflorens\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[750/1357] Processing: Cynanchum viminale\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[760/1357] Processing: Melodinus erianthus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[770/1357] Processing: Spirolobium cambodianum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[780/1357] Processing: Eleutherococcus trifoliatus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[790/1357] Processing: Aristolochia hainanensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[800/1357] Processing: Asarum glabrum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[810/1357] Processing: Leontopodium andersonii\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[820/1357] Processing: Berberis japonica\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[830/1357] Processing: Pauldopia ghorta\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "âœ— Error fetching http://vnredlist.vast.vn/heliotropium-arboreum-blanco-mabb-2017/: HTTPConnectionPool(host='vnredlist.vast.vn', port=80): Read timed out. (read timeout=15)\n",
      "  âœ— Failed to fetch: http://vnredlist.vast.vn/heliotropium-arboreum-blanco-mabb-2017/\n",
      "\n",
      "[840/1357] Processing: Lonicera bournei\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[850/1357] Processing: Alangium tonkinense\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[860/1357] Processing: Hopea ferrea\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[870/1357] Processing: Diospyros mollis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[880/1357] Processing: Rhododendron trancongii\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[890/1357] Processing: Sindora siamensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[900/1357] Processing: Castanopsis tessellata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[910/1357] Processing: Quercus asymmetrica\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[920/1357] Processing: Quercus macrocalyx\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[930/1357] Processing: Hydnocarpus annamensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[940/1357] Processing: Platycarya strobilacea\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[950/1357] Processing: Teucrium ornatum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[960/1357] Processing: Cinnadenia paniculata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[970/1357] Processing: Barringtonia asiatica\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[980/1357] Processing: Magnolia blaoensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[990/1357] Processing: Magnolia nana\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1000/1357] Processing: Pityranthe trichosperma\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1010/1357] Processing: Epicharis cuneata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1020/1357] Processing: Knema saxatilis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1030/1357] Processing: Aeginetia indica\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1040/1357] Processing: Embelia parviflora\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1050/1357] Processing: Malus doumeri\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1060/1357] Processing: Ridsdalea vietnamensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1070/1357] Processing: Sisyrolepis muricata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1080/1357] Processing: Schisandra sphenanthera\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1090/1357] Processing: Camellia ligustrina\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1100/1357] Processing: Knema sessiflora\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1110/1357] Processing: Hapaline locii\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1120/1357] Processing: Asparagus filicinus\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1130/1357] Processing: Carex hanamninhensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1140/1357] Processing: Thoracostachyum vietnamense\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "âœ— Error fetching http://vnredlist.vast.vn/dioscorea-membranacea-craib-1914/: HTTPConnectionPool(host='vnredlist.vast.vn', port=80): Read timed out. (read timeout=15)\n",
      "  âœ— Failed to fetch: http://vnredlist.vast.vn/dioscorea-membranacea-craib-1914/\n",
      "\n",
      "[1150/1357] Processing: Paris vietnamensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1160/1357] Processing: Bulbophyllum astelidum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1170/1357] Processing: Cleisostoma equestre\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1180/1357] Processing: Dendrobium bellatulum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1190/1357] Processing: Dendrobium henryi\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1200/1357] Processing: Dendrobium palpebrae\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1210/1357] Processing: Goodyera rhombodoides\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1220/1357] Processing: Nervilia gracilis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1230/1357] Processing: Paphiopedilum gratrixianum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1240/1357] Processing: Paphiopedilum vietnamense\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1250/1357] Processing: Vanda vietnamica\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1260/1357] Processing: Oryza rufipogon\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1270/1357] Processing: Newmania sontraensis\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1280/1357] Processing: Pinus henryi\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1290/1357] Processing: Cycas pectinata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1300/1357] Processing: Cycas edentata\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1310/1357] Processing: Alsophila spinulosa\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1320/1357] Processing: Udotea flabellum\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1330/1357] Processing: Hydropuntia eucheumatoides\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1340/1357] Processing: Kappaphycus cottonii\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "[1350/1357] Processing: Cantharellus cibarius\n",
      "  âœ“ Successfully extracted data\n",
      "\n",
      "  ğŸ’¾ Saved intermediate results to vnredlist_status.json\n",
      "\n",
      "================================================================================\n",
      "âœ“ Processing complete!\n",
      "  Successfully extracted: 1355 species\n",
      "  Failed: 2 species\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "all_species_details = []\n",
    "failed_urls = []\n",
    "\n",
    "if not df_species.empty:\n",
    "    total_species = len(df_species)\n",
    "    print(f\"Starting to process {total_species} species...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for idx, row in df_species.iterrows():\n",
    "        species_url = row['url']\n",
    "        scientific_name = row.get('scientific_name', 'Unknown')\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (idx + 1) % 10 == 0 or idx == 0:\n",
    "            print(f\"\\n[{idx + 1}/{total_species}] Processing: {scientific_name}\")\n",
    "        \n",
    "        # Fetch the species page\n",
    "        soup = fetch_species_page(species_url)\n",
    "        \n",
    "        if soup:\n",
    "            try:\n",
    "                # Extract species details\n",
    "                species_data = extract_species_details(species_url, soup)\n",
    "                all_species_details.append(species_data)\n",
    "                \n",
    "                if (idx + 1) % 10 == 0:\n",
    "                    print(f\"  âœ“ Successfully extracted data\")\n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error extracting data from {species_url}: {e}\")\n",
    "                failed_urls.append(species_url)\n",
    "        else:\n",
    "            print(f\"  âœ— Failed to fetch: {species_url}\")\n",
    "            failed_urls.append(species_url)\n",
    "        \n",
    "        # Wait 1-2 seconds between requests\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Save intermediate results every 10 species\n",
    "        if (idx + 1) % 10 == 0:\n",
    "            intermediate_file = f'vnredlist_status.json'\n",
    "            with open(intermediate_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_species_details, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"\\n  ğŸ’¾ Saved intermediate results to {intermediate_file}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"âœ“ Processing complete!\")\n",
    "    print(f\"  Successfully extracted: {len(all_species_details)} species\")\n",
    "    print(f\"  Failed: {len(failed_urls)} species\")\n",
    "    print(\"=\" * 80)\n",
    "else:\n",
    "    print(\"No species data to process.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18157e7d",
   "metadata": {},
   "source": [
    "## 7. Save Results to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dbc035",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_species_details:\n",
    "    # Save to JSON file\n",
    "    with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:\n",
    "        json.dump(all_species_details, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"âœ“ All species details saved to: {OUTPUT_JSON}\")\n",
    "    print(f\"  Total records: {len(all_species_details)}\")\n",
    "    \n",
    "    # Save failed URLs for retry\n",
    "    if failed_urls:\n",
    "        failed_file = 'failed_species_urls.txt'\n",
    "        with open(failed_file, 'w') as f:\n",
    "            f.write('\\n'.join(failed_urls))\n",
    "        print(f\"\\nâœ“ Failed URLs saved to: {failed_file}\")\n",
    "        print(f\"  Total failed: {len(failed_urls)}\")\n",
    "else:\n",
    "    print(\"No data to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11fd31",
   "metadata": {},
   "source": [
    "## 8. Display Sample Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c10e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_species_details:\n",
    "    print(\"\\nSample extracted species data:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Show first 3 species\n",
    "    for i, species in enumerate(all_species_details[:3], 1):\n",
    "        print(f\"\\n{i}. {species['scientific_name']['value']}\")\n",
    "        print(f\"   Common name: {species['common_name']['value']}\")\n",
    "        print(f\"   Kingdom: {species['kingdom_latin']}\")\n",
    "        print(f\"   Phylum: {species['phylum_latin']}\")\n",
    "        print(f\"   Class: {species['class_latin']}\")\n",
    "        print(f\"   Order: {species['order_latin']}\")\n",
    "        print(f\"   Family: {species['family_latin']}\")\n",
    "        if species['laws']:\n",
    "            print(f\"   Conservation Status: {species['laws'][0]['value']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13978b",
   "metadata": {},
   "source": [
    "## 9. Statistics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29df6ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all_species_details:\n",
    "    print(\"\\nExtraction Statistics:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Count species with complete taxonomic information\n",
    "    complete_taxonomy = sum(1 for s in all_species_details \n",
    "                           if s['kingdom_latin'] and s['phylum_latin'] \n",
    "                           and s['class_latin'] and s['order_latin'] \n",
    "                           and s['family_latin'])\n",
    "    \n",
    "    # Count species with conservation status\n",
    "    with_status = sum(1 for s in all_species_details if s['laws'])\n",
    "    \n",
    "    # Count species with common names\n",
    "    with_common_name = sum(1 for s in all_species_details \n",
    "                          if s['common_name']['value'])\n",
    "    \n",
    "    print(f\"Total species extracted: {len(all_species_details)}\")\n",
    "    print(f\"Species with complete taxonomy: {complete_taxonomy} ({complete_taxonomy/len(all_species_details)*100:.1f}%)\")\n",
    "    print(f\"Species with conservation status: {with_status} ({with_status/len(all_species_details)*100:.1f}%)\")\n",
    "    print(f\"Species with common names: {with_common_name} ({with_common_name/len(all_species_details)*100:.1f}%)\")\n",
    "    print(f\"Failed extractions: {len(failed_urls)}\")\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97e48228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1355"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_species_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21953596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total species in original list: 1356\n",
      "Total species extracted: 1354\n",
      "Total missing species: 5\n"
     ]
    }
   ],
   "source": [
    "# Find missing species details\n",
    "all_scientific_names = set(df_species['scientific_name'].dropna().str.strip())\n",
    "extracted_scientific_names = set(s['scientific_name']['value'] for s in all_species_details if s['scientific_name']['value'])\n",
    "missing_species = all_scientific_names - extracted_scientific_names\n",
    "print(f\"Total species in original list: {len(all_scientific_names)}\")\n",
    "print(f\"Total species extracted: {len(extracted_scientific_names)}\")\n",
    "print(f\"Total missing species: {len(missing_species)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6248e427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrying 2 failed URLs...\n",
      "================================================================================\n",
      "\n",
      "Retrying [1/2]: http://vnredlist.vast.vn/heliotropium-arboreum-blanco-mabb-2017/\n",
      "  âœ“ Successfully extracted data on retry\n",
      "\n",
      "Retrying [2/2]: http://vnredlist.vast.vn/dioscorea-membranacea-craib-1914/\n",
      "  âœ“ Successfully extracted data on retry\n",
      "\n",
      "================================================================================\n",
      "Retry complete.\n",
      "Total records after retry: 2\n"
     ]
    }
   ],
   "source": [
    "# Run the code on the failed URLs to retry fetching them\n",
    "failed_species_details = []\n",
    "if failed_urls:\n",
    "    print(f\"\\nRetrying {len(failed_urls)} failed URLs...\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for idx, species_url in enumerate(failed_urls):\n",
    "        print(f\"\\nRetrying [{idx + 1}/{len(failed_urls)}]: {species_url}\")\n",
    "        \n",
    "        # Fetch the species page\n",
    "        soup = fetch_species_page(species_url)\n",
    "        \n",
    "        if soup:\n",
    "            try:\n",
    "                # Extract species details\n",
    "                species_data = extract_species_details(species_url, soup)\n",
    "                failed_species_details.append(species_data)\n",
    "                print(f\"  âœ“ Successfully extracted data on retry\")\n",
    "            except Exception as e:\n",
    "                print(f\"  âœ— Error extracting data from {species_url} on retry: {e}\")\n",
    "        else:\n",
    "            print(f\"  âœ— Failed to fetch again: {species_url}\")\n",
    "        \n",
    "        # Wait 1-2 seconds between requests\n",
    "        time.sleep(2)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Retry complete.\")\n",
    "    print(f\"Total records after retry: {len(failed_species_details)}\")\n",
    "    \n",
    "    # Save updated results\n",
    "    with open(\"vnredlist_status_failed.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(failed_species_details, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20cb3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save updated results\n",
    "with open(\"vnredlist_status_new.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_species_details, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
